{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Swarm üêù\n",
    "OpenAI has recently released Swarm, an open-source AI agent orchestration tool designed to streamline the process of building AI agents using clean and simple Python code. With Swarm, you can connect multiple agents to perform complex tasks. This is an exciting tool for those exploring the future of AI automation.\n",
    "\n",
    "In this notebook, I'll provide an in-depth walkthrough of the Swarm Python library, including how to use it to create an customer support agent system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Swarm\n",
    "Before using Swarm, ensure you have Python 3.10 or later installed. To install Swarm, use the following command: `pip install git+https://github.com/openai/swarm.git`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After installation, import the necessary modules to get started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from swarm import Swarm, Agent\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swarm agents use GPT-4o-mini as the default model. To reduce costs, you can explicitly set whatever model you want as your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create an entry-point agent (Agent A) that initialises communication and we define a function to transfer control to another agent (Agent B):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_to_agent_b():\n",
    "    return agent_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we create Agent A and define its behavior. In this case, this agent is instructed to be a generic helpful agent, and its function is to transfer the tasks to Agent B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_a = Agent(\n",
    "    name=\"Agent A\",\n",
    "    model=model,\n",
    "    instructions=\"You are a helpful agent\",\n",
    "    functions=[transfer_to_agent_b]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create Agent B and define its behavior. In this case, Agent B is going to always give the same response. I have set up this in this way so we can check that it is actually working!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_b = Agent(\n",
    "    name=\"Agent B\",\n",
    "    model=model,\n",
    "    instructions=\"Always reply with 'Bzzzz'\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when a user interacts with an agent, OpenAI‚Äôs API with function calling enabled examines the input. This is what happens behind the scenes:\n",
    "\n",
    "- Analyse Input: The model analyses the user‚Äôs intent based on the message's context.\n",
    "- Check Functions: The system matches the intent with the available functions.\n",
    "- Execute Function: The best-fitting function is executed, or the model responds without invoking a function if none is applicable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start the Swarm, instantiate a Swarm client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Swarm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we call its run function and we enable debug mode to track interactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[97m[\u001b[90m2024-11-21 12:57:24\u001b[97m]\u001b[90m Getting chat completion for...: [{'role': 'system', 'content': 'You are a helpful agent'}, {'role': 'user', 'content': 'Let me talk to a different agent'}]\u001b[0m\n",
      "\u001b[97m[\u001b[90m2024-11-21 12:57:25\u001b[97m]\u001b[90m Received completion: ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_YzFP9WQZftROW10OSsqFqRUg', function=Function(arguments='{}', name='transfer_to_agent_b'), type='function')])\u001b[0m\n",
      "\u001b[97m[\u001b[90m2024-11-21 12:57:25\u001b[97m]\u001b[90m Processing tool call: transfer_to_agent_b with arguments {}\u001b[0m\n",
      "\u001b[97m[\u001b[90m2024-11-21 12:57:25\u001b[97m]\u001b[90m Getting chat completion for...: [{'role': 'system', 'content': \"Always reply with 'Bzzzz'\"}, {'role': 'user', 'content': 'Let me talk to a different agent'}, {'content': None, 'refusal': None, 'role': 'assistant', 'audio': None, 'function_call': None, 'tool_calls': [{'id': 'call_YzFP9WQZftROW10OSsqFqRUg', 'function': {'arguments': '{}', 'name': 'transfer_to_agent_b'}, 'type': 'function'}], 'sender': 'Agent A'}, {'role': 'tool', 'tool_call_id': 'call_YzFP9WQZftROW10OSsqFqRUg', 'tool_name': 'transfer_to_agent_b', 'content': '{\"assistant\": \"Agent B\"}'}]\u001b[0m\n",
      "\u001b[97m[\u001b[90m2024-11-21 12:57:25\u001b[97m]\u001b[90m Received completion: ChatCompletionMessage(content='Bzzzz', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\u001b[0m\n",
      "\u001b[97m[\u001b[90m2024-11-21 12:57:25\u001b[97m]\u001b[90m Ending turn.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = client.run(\n",
    "    agent=agent_a,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Let me talk to a different agent\"}],\n",
    "    debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bzzzz\n"
     ]
    }
   ],
   "source": [
    "print(response.messages[-1].get('content'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context variables are a powerful feature in Swarm that allow agents to share additional information beyond the user's input. They function as a dictionary, allows you to pass key-value pairs that imrove the flow of communication and make the agent system more dynamic and personalised.\n",
    "\n",
    "In simpler terms, they are a way to \"pass notes\" between agents For instance, if a customer interacts with a support agent, the agent might need to pass along the customer's name, issue, or preferences to another agent. Context variables ensure this information is available wherever needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To pass context variables, Swarm provides a Result class, which encapsulates the response, the target agent, and the context variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from swarm.types import Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a function in the sales agent that passes context variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def talk_to_sales():\n",
    "    print('Talk to sales function triggered')\n",
    "    return Result(\n",
    "        value=\"Done\",\n",
    "        agent=sales_agent,\n",
    "        conext_variables={\"department\": \"sales\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sales agent will use the context variable customer_name in its response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_agent = Agent(\n",
    "    name = \"Sales Agent\",\n",
    "    instructions=lambda context: f\"Always greet the user {context['customer_name']}.\",\n",
    "    model = model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the customer agent and include the talk_to_sales function in its list of callable functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_agent = Agent(\n",
    "    name = \"Customer Agent\",\n",
    "    model = model,\n",
    "    functions = [talk_to_sales]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the Swarm run method to initialise the conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[97m[\u001b[90m2024-11-20 13:17:19\u001b[97m]\u001b[90m Getting chat completion for...: [{'role': 'system', 'content': 'You are a helpful agent.'}, {'role': 'user', 'content': 'Transfer me to sales'}]\u001b[0m\n",
      "\u001b[97m[\u001b[90m2024-11-20 13:17:19\u001b[97m]\u001b[90m Received completion: ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_dY9CqsUKNus3QlZUAMQ3eZ6W', function=Function(arguments='{}', name='talk_to_sales'), type='function')])\u001b[0m\n",
      "\u001b[97m[\u001b[90m2024-11-20 13:17:19\u001b[97m]\u001b[90m Processing tool call: talk_to_sales with arguments {}\u001b[0m\n",
      "Talk to sales function triggered\n",
      "\u001b[97m[\u001b[90m2024-11-20 13:17:19\u001b[97m]\u001b[90m Getting chat completion for...: [{'role': 'system', 'content': 'Always greet the user Chris.'}, {'role': 'user', 'content': 'Transfer me to sales'}, {'content': None, 'refusal': None, 'role': 'assistant', 'audio': None, 'function_call': None, 'tool_calls': [{'id': 'call_dY9CqsUKNus3QlZUAMQ3eZ6W', 'function': {'arguments': '{}', 'name': 'talk_to_sales'}, 'type': 'function'}], 'sender': 'Customer Agent'}, {'role': 'tool', 'tool_call_id': 'call_dY9CqsUKNus3QlZUAMQ3eZ6W', 'tool_name': 'talk_to_sales', 'content': 'Done'}]\u001b[0m\n",
      "\u001b[97m[\u001b[90m2024-11-20 13:17:20\u001b[97m]\u001b[90m Received completion: ChatCompletionMessage(content=\"Hello Chris! I've connected you to sales. How can I assist you today?\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\u001b[0m\n",
      "\u001b[97m[\u001b[90m2024-11-20 13:17:20\u001b[97m]\u001b[90m Ending turn.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "customer_response = client.run(\n",
    "    agent=customer_agent,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Transfer me to sales\"}],\n",
    "    context_variables={\"customer_name\": \"Chris\"},\n",
    "    debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales Agent\n",
      "{'customer_name': 'Chris'}\n",
      "Hello Chris! I've connected you to sales. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "print(customer_response.agent.name)\n",
    "print(customer_response.context_variables)\n",
    "print(customer_response.messages[-1].get(\"content\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study: Developing a Multi-Agent Customer Support System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you are building a customer support system for an online store that specialises in unique products like artisanal honey and beekeeping supplies. The goal is to create an intelligent system that can:\n",
    "\n",
    "- Understand and route user queries to the appropriate support team.\n",
    "- Handle common scenarios such as refunds and sales inquiries.\n",
    "- Provide a personalised experience by dynamically responding to user input and utilising shared context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The system will consist of three agents:\n",
    "\n",
    "- Decision Agent: Acts as the first point of contact, determining the nature of the user‚Äôs query and routing it to the appropriate agent.\n",
    "- Sales Agent: Handles inquiries about products, upsells items, and enthusiastically engages with customers.\n",
    "- Refunds Agent: Manages refund requests.\n",
    "\n",
    "Each agent is designed with specific instructions and functions to process user input, ensuring efficient query resolution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to BeeBuzz Support System. How can I help you today?\n",
      "\n",
      "--- Refund Conversation ---\n",
      "Customer Query: I need a refund for my latest purchase.\n",
      "Processing refund for Chris: Item ID item_123, Reason: Product didn't arrive\n",
      "Refunds Agent\n",
      "Your refund has been successfully processed. If you have any further questions, feel free to ask!\n",
      "\n",
      "--- Sales Conversation ---\n",
      "Customer Query: Tell me more about your latest product.\n",
      "Sales Agent\n",
      "Our latest product at BeeBuzz is the \"Alpine Wildflower Honey.\" This unique honey is made from the nectar of alpine wildflowers, which gives it a distinct, floral aroma and a delicate sweetness. It is harvested from hives situated in high-altitude areas, ensuring that it is not only pure but also rich in antioxidants and beneficial enzymes.\n",
      "\n",
      "In addition to its delightful flavor, Alpine Wildflower Honey is perfect for those who appreciate artisanal, small-batch products. It can be enjoyed in various ways, such as drizzling over yogurt, spreading on toast, or sweetening your favorite tea.\n",
      "\n",
      "If you are interested in exploring this exquisite honey or have any questions about our other products, please let me know!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the function for processing refunds\n",
    "def process_refund(context_variables):\n",
    "    \"\"\"Process a refund for an item.\"\"\"\n",
    "    item_id = context_variables.get('item_id', 'Unknown Item')\n",
    "    reason = context_variables.get('reason', 'No reason provided')\n",
    "    customer_name = context_variables.get('customer_name', 'Customer')\n",
    "    print(f\"Processing refund for {customer_name}: Item ID {item_id}, Reason: {reason}\")\n",
    "    return f\"Success! Refund for {item_id} has been processed because {reason}.\"\n",
    "\n",
    "# Define the Refunds Agent\n",
    "refunds_agent = Agent(\n",
    "    name=\"Refunds Agent\",\n",
    "    instructions=\"You handle refund requests. Use the 'process_refund' function to process refunds.\",\n",
    "    functions=[process_refund]\n",
    ")\n",
    "\n",
    "# Define the Sales Agent\n",
    "sales_agent = Agent(\n",
    "    name=\"Sales Agent\",\n",
    "    instructions=\"You provide information what customer asks regarding BeeBuzz products and assist with sales inquiries. BeeBuzz products are in unique products like artisanal honey and beekeeping supplies \"\n",
    ")\n",
    "\n",
    "# Define the Decision Agent\n",
    "def determine_agent(context_variables):\n",
    "    \"\"\"Determine which agent should handle the user's request.\"\"\"\n",
    "    query = context_variables.get('query', '').lower()\n",
    "    if \"refund\" in query:\n",
    "        return refunds_agent\n",
    "    else:\n",
    "        return sales_agent\n",
    "\n",
    "decision_agent = Agent(\n",
    "    name=\"Decision Agent\",\n",
    "    instructions=\"Based on the user's request, determine whether to transfer to the Sales Agent or Refunds Agent.\",\n",
    "    functions=[determine_agent]\n",
    ")\n",
    "\n",
    "# Function to run the conversation\n",
    "def run_conversation(agent, query, context_variables):\n",
    "    context_variables['query'] = query\n",
    "    message = {\"role\": \"user\", \"content\": query}\n",
    "    response = client.run(\n",
    "        agent=agent,\n",
    "        messages=[message],\n",
    "        context_variables=context_variables,\n",
    "        execute_tools=True,\n",
    "        debug=False\n",
    "    )\n",
    "    print(response.agent.name)\n",
    "    return response\n",
    "\n",
    "# Full conversation simulation\n",
    "def full_conversation():\n",
    "    print(\"Welcome to BeeBuzz Support System. How can I help you today?\")\n",
    "\n",
    "    # Simulate a refund conversation\n",
    "    refund_context = {\n",
    "        \"customer_name\": \"Chris\",\n",
    "        \"item_name\": \"Bee Wax Candle\",\n",
    "        \"item_id\": \"item_123\",\n",
    "        \"reason\": \"Product didn't arrive\"\n",
    "    }\n",
    "    refund_query = \"I need a refund for my latest purchase.\"\n",
    "\n",
    "    print(\"\\n--- Refund Conversation ---\")\n",
    "    print(f\"Customer Query: {refund_query}\")\n",
    "    response = run_conversation(decision_agent, refund_query, refund_context)\n",
    "    print(response.messages[-1].get(\"content\"))\n",
    "\n",
    "    # Simulate a sales conversation\n",
    "    sales_context = {\n",
    "        \"customer_name\": \"Chris\",\n",
    "        \"item_name\": \"Honey Jar\"\n",
    "    }\n",
    "    sales_query = \"Tell me more about your latest product.\"\n",
    "\n",
    "    print(\"\\n--- Sales Conversation ---\")\n",
    "    print(f\"Customer Query: {sales_query}\")\n",
    "    response = run_conversation(decision_agent, sales_query, sales_context)\n",
    "    print(response.messages[-1].get(\"content\"))\n",
    "\n",
    "# Run the full conversation\n",
    "full_conversation()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
